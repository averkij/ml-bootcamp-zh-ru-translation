{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mlbootcamp.ru/round/26/tasks/\n",
    "\n",
    "Chinese is a wonderful language. Let's see what can we build to understand the meaning of the sentence and make a proper translation system.\n",
    "\n",
    "Our main task is to receive a Russian translation for a Chinese text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import pinyin.cedict\n",
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a random sentences from the BBC news channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"摆在唐宁街面前的是一系列重大决策：何时行动？解除哪些限制？如何控制病毒传播？如何权衡短期内挽救生命、长期内挽救经济和社会？\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical Chinese word consists of 2 or 3 characters. We can see that there are no spaces between words. Let's use the jieba library to split the sentence to words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = jieba.lcut(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['摆在',\n",
       " '唐宁街',\n",
       " '面前',\n",
       " '的',\n",
       " '是',\n",
       " '一系列',\n",
       " '重大',\n",
       " '决策',\n",
       " '：',\n",
       " '何时',\n",
       " '行动',\n",
       " '？',\n",
       " '解除',\n",
       " '哪些']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can slightly understand what's it about by use the pinyin lib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = []\n",
    "for word in words:\n",
    "    tr = pinyin.cedict.translate_word(word)\n",
    "    if tr:\n",
    "        trans.append(tr[0])\n",
    "    else:\n",
    "        trans.append(\"—\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['—',\n",
       " 'Downing Street (London)',\n",
       " 'in front of',\n",
       " 'aim',\n",
       " 'variant of 是[shi4]',\n",
       " 'a series of',\n",
       " 'great',\n",
       " 'strategic decision',\n",
       " '—',\n",
       " 'when',\n",
       " 'operation',\n",
       " '—',\n",
       " 'to remove',\n",
       " 'which ones?']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive approach is to translate with dictionary. We take the first Chinese-Russian dictionary thet we can find, clean it and use to translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_ru = pickle.load(open(\"zh_ru.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2616"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zh_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(word):\n",
    "    if word in zh_ru:\n",
    "        return zh_ru[word]\n",
    "    else:\n",
    "        return \"пушкин\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "摆在 пушкин\n",
      "唐宁街 пушкин\n",
      "面前 пушкин\n",
      "的 пушкин\n",
      "是 ['представлять', 'представить']\n",
      "一系列 ['серия']\n",
      "重大 пушкин\n",
      "决策 пушкин\n",
      "： пушкин\n",
      "何时 пушкин\n",
      "行动 пушкин\n",
      "？ пушкин\n",
      "解除 пушкин\n",
      "哪些 пушкин\n",
      "限制 пушкин\n",
      "？ пушкин\n",
      "如何 ['как?']\n",
      "控制 пушкин\n",
      "病毒传播 пушкин\n",
      "？ пушкин\n",
      "如何 ['как?']\n",
      "权衡 пушкин\n",
      "短期内 пушкин\n",
      "挽救 пушкин\n",
      "生命 ['жизнь']\n",
      "、 пушкин\n",
      "长期 пушкин\n",
      "内 пушкин\n",
      "挽救 пушкин\n",
      "经济 ['экономика']\n",
      "和 ['с']\n",
      "社会 пушкин\n",
      "？ пушкин\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word, translate(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data.json', 'w', encoding='utf8') as f:\n",
    "    json.dump(zh_ru, f, ensure_ascii=False)\n",
    "    \n",
    "#     with io.open('filename', 'w', encoding='utf8') as json_file:\n",
    "#     json.dump(u\"ברי צקלה\", json_file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'r', encoding='utf8') as f:\n",
    "    a = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['а']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['而']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace all non Chinese characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# LHan = [[0x2E80, 0x2E99],    # Han # So  [26] CJK RADICAL REPEAT, CJK RADICAL RAP\n",
    "#         [0x2E9B, 0x2EF3],    # Han # So  [89] CJK RADICAL CHOKE, CJK RADICAL C-SIMPLIFIED TURTLE\n",
    "#         [0x2F00, 0x2FD5],    # Han # So [214] KANGXI RADICAL ONE, KANGXI RADICAL FLUTE\n",
    "#         0x3005,              # Han # Lm       IDEOGRAPHIC ITERATION MARK\n",
    "#         0x3007,              # Han # Nl       IDEOGRAPHIC NUMBER ZERO\n",
    "#         [0x3021, 0x3029],    # Han # Nl   [9] HANGZHOU NUMERAL ONE, HANGZHOU NUMERAL NINE\n",
    "#         [0x3038, 0x303A],    # Han # Nl   [3] HANGZHOU NUMERAL TEN, HANGZHOU NUMERAL THIRTY\n",
    "#         0x303B,              # Han # Lm       VERTICAL IDEOGRAPHIC ITERATION MARK\n",
    "#         [0x3400, 0x4DB5],    # Han # Lo [6582] CJK UNIFIED IDEOGRAPH-3400, CJK UNIFIED IDEOGRAPH-4DB5\n",
    "#         [0x4E00, 0x9FC3],    # Han # Lo [20932] CJK UNIFIED IDEOGRAPH-4E00, CJK UNIFIED IDEOGRAPH-9FC3\n",
    "#         [0xF900, 0xFA2D],    # Han # Lo [302] CJK COMPATIBILITY IDEOGRAPH-F900, CJK COMPATIBILITY IDEOGRAPH-FA2D\n",
    "#         [0xFA30, 0xFA6A],    # Han # Lo  [59] CJK COMPATIBILITY IDEOGRAPH-FA30, CJK COMPATIBILITY IDEOGRAPH-FA6A\n",
    "#         [0xFA70, 0xFAD9],    # Han # Lo [106] CJK COMPATIBILITY IDEOGRAPH-FA70, CJK COMPATIBILITY IDEOGRAPH-FAD9\n",
    "#         [0x20000, 0x2A6D6],  # Han # Lo [42711] CJK UNIFIED IDEOGRAPH-20000, CJK UNIFIED IDEOGRAPH-2A6D6\n",
    "#         [0x2F800, 0x2FA1D]]  # Han # Lo [542] CJK COMPATIBILITY IDEOGRAPH-2F800, CJK COMPATIBILITY IDEOGRAPH-2FA1D\n",
    "\n",
    "# def build_re():\n",
    "#     L = []\n",
    "#     for i in LHan:\n",
    "#         if isinstance(i, list):\n",
    "#             f, t = i\n",
    "#             try: \n",
    "#                 f = unichr(f)\n",
    "#                 t = unichr(t)\n",
    "#                 L.append('%s-%s' % (f, t))\n",
    "#             except: \n",
    "#                 pass # A narrow python build, so can't use chars > 65535 without surrogate pairs!\n",
    "\n",
    "#         else:\n",
    "#             try:\n",
    "#                 L.append(unichr(i))\n",
    "#             except:\n",
    "#                 pass\n",
    "\n",
    "#     RE = '[%s]' % ''.join(L)\n",
    "#     print('RE:', RE.encode('utf-8'))\n",
    "#     return re.compile(RE, re.UNICODE)\n",
    "\n",
    "# RE = build_re()\n",
    "# print(RE.sub('', u'美国').encode('utf-8'))\n",
    "# print(RE.sub('', u'blah').encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = re.compile(r'\\s+')\n",
    "s = re.sub(pattern, ' ', \"Please \\n don't \\t hurt \\x0b me.\")\n",
    "\n",
    "#s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "path = \"D:\\\\ml\\\\ted-talks-transcript\\\\books\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chelovek_ru.txt', 'chelovek_zh.txt', 'idiot_ru.txt', 'idiot_zh.txt', 'izergil_ru.txt', 'izergil_zh.txt', 'lubov_ru.txt', 'lubov_zh.txt', 'mumu_ru.txt', 'mumu_zh.txt', 'ostr_stal_ru.txt', 'ostr_stal_zh.txt', 'sent_ru_ext_ru.txt', 'sent_zh_ext_zh.txt', 'tolst_ru.txt', 'tolst_zh.txt']\n",
      "D:\\ml\\ted-talks-transcript\\books\\*_zh.txt\n",
      "D:\\ml\\ted-talks-transcript\\books\\*_zh.txt\n"
     ]
    }
   ],
   "source": [
    "for f in [filenames for (dirpath, dirnames, filenames) in os.walk(path)]:\n",
    "    types = ['\\*_ru.txt', '\\*_zh.txt']\n",
    "    ru = []\n",
    "    zh = []\n",
    "    \n",
    "    print(f)\n",
    "    \n",
    "    print(path + t)\n",
    "    files = glob.glob(path + types[0])        \n",
    "    ru.extend(files)\n",
    "    \n",
    "    print(path + t)\n",
    "    files = glob.glob(path + types[1])        \n",
    "    zh.extend(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\ml\\\\ted-talks-transcript\\\\books\\\\chelovek_ru.txt',\n",
       " 'D:\\\\ml\\\\ted-talks-transcript\\\\books\\\\idiot_ru.txt',\n",
       " 'D:\\\\ml\\\\ted-talks-transcript\\\\books\\\\izergil_ru.txt',\n",
       " 'D:\\\\ml\\\\ted-talks-transcript\\\\books\\\\lubov_ru.txt',\n",
       " 'D:\\\\ml\\\\ted-talks-transcript\\\\books\\\\mumu_ru.txt',\n",
       " 'D:\\\\ml\\\\ted-talks-transcript\\\\books\\\\ostr_stal_ru.txt',\n",
       " 'D:\\\\ml\\\\ted-talks-transcript\\\\books\\\\sent_ru_ext_ru.txt',\n",
       " 'D:\\\\ml\\\\ted-talks-transcript\\\\books\\\\tolst_ru.txt']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\ml\\\\ted-talks-transcript\\\\books\\\\chelovek_zh.txt',\n",
       " 'D:\\\\ml\\\\ted-talks-transcript\\\\books\\\\idiot_zh.txt',\n",
       " 'D:\\\\ml\\\\ted-talks-transcript\\\\books\\\\izergil_zh.txt',\n",
       " 'D:\\\\ml\\\\ted-talks-transcript\\\\books\\\\lubov_zh.txt',\n",
       " 'D:\\\\ml\\\\ted-talks-transcript\\\\books\\\\mumu_zh.txt',\n",
       " 'D:\\\\ml\\\\ted-talks-transcript\\\\books\\\\ostr_stal_zh.txt',\n",
       " 'D:\\\\ml\\\\ted-talks-transcript\\\\books\\\\sent_zh_ext_zh.txt',\n",
       " 'D:\\\\ml\\\\ted-talks-transcript\\\\books\\\\tolst_zh.txt']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ml\\ted-talks-transcript\\books\\chelovek_ru.txt D:\\ml\\ted-talks-transcript\\books\\chelovek_zh.txt\n",
      "D:\\ml\\ted-talks-transcript\\books\\idiot_ru.txt D:\\ml\\ted-talks-transcript\\books\\idiot_zh.txt\n",
      "D:\\ml\\ted-talks-transcript\\books\\izergil_ru.txt D:\\ml\\ted-talks-transcript\\books\\izergil_zh.txt\n",
      "D:\\ml\\ted-talks-transcript\\books\\lubov_ru.txt D:\\ml\\ted-talks-transcript\\books\\lubov_zh.txt\n",
      "D:\\ml\\ted-talks-transcript\\books\\mumu_ru.txt D:\\ml\\ted-talks-transcript\\books\\mumu_zh.txt\n",
      "D:\\ml\\ted-talks-transcript\\books\\ostr_stal_ru.txt D:\\ml\\ted-talks-transcript\\books\\ostr_stal_zh.txt\n",
      "D:\\ml\\ted-talks-transcript\\books\\sent_ru_ext_ru.txt D:\\ml\\ted-talks-transcript\\books\\sent_zh_ext_zh.txt\n",
      "D:\\ml\\ted-talks-transcript\\books\\tolst_ru.txt D:\\ml\\ted-talks-transcript\\books\\tolst_zh.txt\n"
     ]
    }
   ],
   "source": [
    "for r,z in zip(ru,zh):\n",
    "    print(r,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'[a-zA-Z\\s]+')\n",
    "pattern2 = re.compile(r'[a-zA-Z]+')\n",
    "\n",
    "# s = re.sub(pattern, ' ', \"Please \\n don't \\t hurt \\x0b me.\")\n",
    "\n",
    "with open(\"D:\\\\ml\\\\ted-talks-transcript\\\\books\\\\sent_books_ru.txt\", mode=\"w\", encoding=\"utf-8\") as out_ru, \\\n",
    "     open(\"D:\\\\ml\\\\ted-talks-transcript\\\\books\\\\sent_books_zh.txt\", mode=\"w\", encoding=\"utf-8\") as out_zh:\n",
    "    for r,z in zip(ru,zh):\n",
    "#         print(r,z)\n",
    "        with open(r, mode=\"r\", encoding=\"utf-8\") as in_ru, open(z, mode=\"r\", encoding=\"utf-8\") as in_zh:\n",
    "            lines_ru = in_ru.readlines()\n",
    "            for line_ru in lines_ru:\n",
    "                line_zh = in_zh.readline()\n",
    "                out_ru.write(re.sub(pattern2, '', line_ru.strip()))\n",
    "                out_zh.write(re.sub(pattern, '', line_zh.strip()))\n",
    "                out_ru.write('\\n')\n",
    "                out_zh.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit6ddfec3d72d0445aa5d24384f848b5d9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
