{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel TED subtitles dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct the TED subtitles dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import codecs\n",
    "import os,glob\n",
    "import glob\n",
    "import re\n",
    "\n",
    "#natasha Russian word tokenizer\n",
    "from razdel import tokenize\n",
    "\n",
    "#Chienese word tokenizer\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrixnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix is the dataset crawled from the web and aligned with some probability.\n",
    "\n",
    "https://github.com/facebookresearch/LASER/tree/master/tasks/WikiMatrix\n",
    "\n",
    "I've taken the 30k+ sentences from it with prob=1.06 to add to the TED dataset for further evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\\\ml\\\\ted-talks-transcript\\\\tedDirector\\\\subtitles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 0\n",
    "subtitles = {}\n",
    "\n",
    "for d in [dirpath for (dirpath, dirnames, filenames) in os.walk(path)][1:]:\n",
    "    types = ['\\*.ru.vtt', '\\*.zh-CN.vtt']\n",
    "    pair = []\n",
    "    \n",
    "    for t in types:\n",
    "        files = glob.glob(d + t)\n",
    "        if len(files) == 1:\n",
    "            pair.extend(files)\n",
    "    \n",
    "    if len(pair) == 2:\n",
    "        subtitles[id] = pair\n",
    "        id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2309"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subtitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\ml\\\\ted-talks-transcript\\\\tedDirector\\\\subtitles\\\\-0v7mTvJ8M4\\\\-0v7mTvJ8M4.ru.vtt',\n",
       " 'D:\\\\ml\\\\ted-talks-transcript\\\\tedDirector\\\\subtitles\\\\-0v7mTvJ8M4\\\\-0v7mTvJ8M4.zh-CN.vtt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtitles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['диван-кровать', 'стоит', 'у', 'стены']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.text for t in tokenize('диван-кровать стоит у стены')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_ru = 'D:\\\\ml\\\\ted-talks-transcript\\\\output_ru.txt'\n",
    "output_zh = 'D:\\\\ml\\\\ted-talks-transcript\\\\output_zh.txt'\n",
    "tokens_ru = 'D:\\\\ml\\\\ted-talks-transcript\\\\tokens_ru.txt'\n",
    "tokens_zh = 'D:\\\\ml\\\\ted-talks-transcript\\\\tokens_zh.txt'\n",
    "\n",
    "import random\n",
    "rand = random.randint(0, 2309)\n",
    "\n",
    "with open(output_ru, mode='w', encoding='utf-8') as out_ru, open(output_zh, mode='w', encoding='utf-8') as out_zh, \\\n",
    "        open(tokens_ru, mode='w', encoding='utf-8') as tok_ru, open(tokens_zh, mode='w', encoding='utf-8') as tok_zh:\n",
    "    #or id in [id for id in subtitles][rand:rand+1]:  \n",
    "    for id in [id for id in subtitles]:  \n",
    "        strings = {}\n",
    "        textlines = {'ru': [], 'zh':[]}\n",
    "\n",
    "        sentences = {}\n",
    "        textlines_sent = {'ru': [], 'zh':[]}\n",
    "        \n",
    "        for file in subtitles[id]:\n",
    "            #print(file)\n",
    "            timestamp = ''\n",
    "            \n",
    "            sentence_acc = \"\"\n",
    "            \n",
    "            with open(file, mode='r', encoding='utf-8') as f:                \n",
    "                isRu = bool(re.search('ru\\.vtt$', file))\n",
    "                if isRu:\n",
    "                    lang = 'ru'\n",
    "                else:\n",
    "                    lang = 'zh'\n",
    "                \n",
    "                for line in f.readlines():\n",
    "                    isTimestamp = re.match(\"^\\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d.*\", line)\n",
    "                    \n",
    "                    if isTimestamp:\n",
    "                        if timestamp in strings:\n",
    "                            strings[timestamp][lang] = ' '.join(textlines[lang])\n",
    "                            textlines = {'ru': [], 'zh':[]}\n",
    "                            #print('timestamp')\n",
    "\n",
    "                        #comes out that the second date in timing is not reliable. taking the start time as key.\n",
    "                        timestamp = line[:16]\n",
    "                        if timestamp not in strings:\n",
    "                            strings[timestamp] = {'ru': '', 'zh':''}\n",
    "                    else: \n",
    "                        #filter beginning of the transcription\n",
    "                        if not isTimestamp:\n",
    "                            if (re.match(\"^Переводчик*\", line) != None) | (re.match(\"^Редактор*\", line) != None) | (re.match(\"^\\(Смех\\)*\", line) != None) | (re.match(\"^\\(Музыка\\)*\", line) != None) | (re.match(\"^\\(Аплодисменты\\)*\", line) != None) | (re.match(\"^Спасибо*\", line) != None):\n",
    "                                textlines = {'ru': [], 'zh':[]}\n",
    "                                continue\n",
    "                        \n",
    "                        if timestamp in strings:\n",
    "                            #print('true', lang)\n",
    "                            if len(line.strip()) > 0:\n",
    "                                textlines[lang].append(line.replace('\\t',' ').strip())\n",
    "                            #print(textlines[lang])\n",
    "\n",
    "        for ts in strings:\n",
    "            if (len(strings[ts]['ru']) > 2) & (len(strings[ts]['zh']) > 2):\n",
    "                str_ru = strings[ts]['ru']\n",
    "                str_zh = strings[ts]['zh']\n",
    "                \n",
    "                out_ru.write(str_ru + '\\n')\n",
    "                out_zh.write(str_zh + '\\n')\n",
    "                \n",
    "                #print(' '.join([t.text for t in tokenize(str_ru)]))\n",
    "                #print(' '.join(jieba.lcut(str_zh)))\n",
    "                \n",
    "                tok_ru.write(' '.join([t.text for t in tokenize(str_ru)]) + '\\n')\n",
    "                tok_zh.write(' '.join(jieba.lcut(str_zh)) + '\\n')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#707839\n",
    "#552370"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sent_ru = 'D:\\\\ml\\\\ted-talks-transcript\\\\sent_ru.txt'\n",
    "sent_zh = 'D:\\\\ml\\\\ted-talks-transcript\\\\sent_zh.txt'\n",
    "\n",
    "with open(output_ru, mode='r', encoding='utf-8') as out_ru, open(output_zh, mode='r', encoding='utf-8') as out_zh, \\\n",
    "    open(sent_ru, mode='w', encoding='utf-8') as sen_ru, open(sent_zh, mode='w', encoding='utf-8') as sen_zh:\n",
    "    \n",
    "    start = True\n",
    "    end = False\n",
    "    sentence_ru = \"\"\n",
    "    sentence_zh = \"\"\n",
    "    \n",
    "    for line_ru in out_ru.readlines():\n",
    "        line_zh = out_zh.readline()\n",
    "        \n",
    "        start = line_ru[:1].upper() == line_ru[:1]            \n",
    "        end = re.match(\".*[\\.!?…]$\", line_ru) != None\n",
    "        \n",
    "#         print(line_ru)\n",
    "#         print(line_zh)\n",
    "                    \n",
    "        sentence_ru = sentence_ru + \" \" + line_ru.strip()\n",
    "        sentence_zh = sentence_zh + \" \" + line_zh.strip()\n",
    "            \n",
    "        if end:  \n",
    "            sent_len = len([t.text for t in tokenize(sentence_ru)])\n",
    "            if (sent_len > 10) * (sent_len < 45):\n",
    "                sen_ru.write(sentence_ru + '\\n')\n",
    "                sen_zh.write(sentence_zh + '\\n')\n",
    "                #print(sentence_ru)\n",
    "                #print(sentence_zh)                \n",
    "                #print()\n",
    "                \n",
    "            sentence_ru = \"\"\n",
    "            sentence_zh = \"\"\n",
    "\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refinining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_corpus = pd.read_csv('D:\\\\ml\\\\ted-talks-transcript\\\\output.txt', delimiter='\\t', names=['ru', 'zh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_ru, mode='r', encoding='utf-8') as out_ru"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit6ddfec3d72d0445aa5d24384f848b5d9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
